{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from random import randint\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.feature_extraction import image\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_gabor(size, shift, sigma, rotation, phase_shift, frequency):\n",
    "    radius = (int((size[0]/2.0)), int((size[1]/2.0)))\n",
    "    [x, y] = np.meshgrid(range(-radius[0], radius[0]), range(-radius[1], radius[1])) # a BUG is fixed in this line\n",
    "    x = x - int(shift[0])\n",
    "    y = y - int(shift[1])\n",
    "    x = x * frequency\n",
    "    y = y * frequency\n",
    "    tmp = x * np.cos(rotation) + y * np.sin(rotation) + phase_shift\n",
    "    radius = (int(size[0]/2.0), int(size[1]/2.0))\n",
    "    [x, y] = np.meshgrid(range(-radius[0], radius[0]), range(-radius[1], radius[1])) # a BUG is fixed in this line\n",
    "    \n",
    "    x = x - int(shift[0])\n",
    "    y = y - int(shift[1])\n",
    "    x1 = x * np.cos(rotation) + y * np.sin(rotation)\n",
    "    y1 = -x * np.sin(rotation) + y * np.cos(rotation)\n",
    "    \n",
    "    sinusoid = np.cos(tmp)\n",
    "    \n",
    "    gauss = np.e * np.exp(np.negative(0.5 * ((x1**2 / sigma[0]**2) + (y1**2 / sigma[1]**2)))) \n",
    "    gauss = gauss / 2*np.pi * sigma[0] * sigma[1]\n",
    "    \n",
    "    gabor = gauss * sinusoid\n",
    "    return gabor\n",
    "\n",
    "def open_norm(path,verbose=False):\n",
    "    raw = np.array(PIL.Image.open(path).convert(\"L\"))\n",
    "    norm = (raw - np.mean(raw)) / np.std(raw)\n",
    "    \n",
    "    if verbose:\n",
    "        return raw, norm\n",
    "    else:\n",
    "        return norm\n",
    "    \n",
    "def linear_convolution(center, slide): \n",
    "    if (center.shape != slide.shape):\n",
    "        return\n",
    "    padded_slide = np.zeros((center.shape[0],center.shape[1]*3))\n",
    "    padded_slide[0:,center.shape[1]:center.shape[1]*2] = center\n",
    "    #plt.imshow(padded_slide,origin=\"lower\")\n",
    "    #plt.show()\n",
    "    estimate = np.zeros([center.shape[1]*2])\n",
    "    for x in range(center.shape[1]*2):\n",
    "        dot = np.sum(padded_slide[0:,0+x:center.shape[1]+x] * slide)\n",
    "        estimate[x] = dot\n",
    "    #plt.plot(estimate)\n",
    "    #plt.show()\n",
    "    return np.abs(estimate)\n",
    "    \n",
    "def double_convolve(normal, shifted, image, pupillary_distance):\n",
    "    \n",
    "    normal_convolved = signal.convolve2d(image, normal, boundary='symm', mode='same')\n",
    "    shifted_convolved = signal.convolve2d(image, shifted, boundary='symm', mode='same')\n",
    "    \n",
    "    return_shape = image.shape\n",
    "    \n",
    "    realigned = np.zeros(return_shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    normal_convolved = normal_convolved[0:,0:-pupillary_distance]\n",
    "    shifted_convolved = shifted_convolved[0:,pupillary_distance:]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    diff = np.subtract(normal_convolved, shifted_convolved)\n",
    "    mul = normal_convolved * shifted_convolved\n",
    "    #plt.imshow(mul,cmap=\"nipy_spectral\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #REMOVE BELOW COMMENTS TO THRESH SUBHALF VALUES\n",
    "    #low_values_flags = mul <= 0 #mul.max()*0.5  # Where values are low\n",
    "    #mul[low_values_flags] = 0  # All low values set to 0\n",
    "    realigned[0:,pupillary_distance:] = mul\n",
    "    return np.abs(realigned)\n",
    "\n",
    "def scale_disparity(activity_map, disparity_map):\n",
    "    scaled_disparity = np.zeros([activity_map.shape[0],activity_map.shape[1],disparity_map.shape[0]])\n",
    "    scaled_disparity[:,:] = disparity_map\n",
    "    for x in range(activity_map.shape[0]):\n",
    "        for y in range(activity_map.shape[1]):\n",
    "            scaled_disparity[x,y] = activity_map[x,y] * scaled_disparity[x,y]\n",
    "            \n",
    "    return scaled_disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def distance(x0, y0, x1, y1):\n",
    "  return np.sqrt(pow(x0-x1,2) + pow(y0-y1,2))\n",
    "\n",
    "class LGN: \n",
    "  \"\"\"\n",
    "  this class defines a model which generates binocular spontaneous activity\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, width = 128, p = 0.5, r = 1.0, t = 1, trans = 0.0,\n",
    "    make_wave = True, num_layers=2, random_seed=0):\n",
    "    random.seed(random_seed)\n",
    "    self.width = width\n",
    "    self.p = p\n",
    "    self.r = r\n",
    "    self.t = t\n",
    "    self.trans = trans\n",
    "    self.num_layers = num_layers\n",
    "    if make_wave:\n",
    "      self.reset_wave()\n",
    "\n",
    "  def reset_wave(self):\n",
    "    \"\"\" create another random wave \"\"\"\n",
    "    # setting up the network\n",
    "    w = self.width\n",
    "    self.recruitable = np.random.rand(self.num_layers, w, w) < self.p\n",
    "    self.tot_recruitable = len(np.where(self.recruitable)[0])\n",
    "    self.tot_recruitable_active = 0\n",
    "    self.tot_active = 0\n",
    "    self.active = np.zeros([self.num_layers,w,w],bool)\n",
    "    self.active_neighbors = np.zeros([self.num_layers,w,w],int)\n",
    "    self.activated = []; # the recently active nodes\n",
    "    \n",
    "    if self.tot_recruitable > 0:\n",
    "      while self.fraction_active() < 0.2:\n",
    "        self.activate()  \n",
    "\n",
    "  def fraction_active(self):\n",
    "    \"\"\" returns the fraction of potentially recruitable cells which are active \"\"\"\n",
    "    if self.tot_recruitable > 0:\n",
    "      return float(self.tot_recruitable_active) / self.tot_recruitable\n",
    "    else:\n",
    "      return nan\n",
    "\n",
    "  def propagate(self):\n",
    "    \"\"\" propagate the activity if a valid node has been activated \"\"\"\n",
    "    # activated only has recruitable and currently inactive members\n",
    "    while len(self.activated) > 0:\n",
    "      act_l, act_x, act_y = self.activated.pop()\n",
    "      self.active[act_l,act_x,act_y] = True\n",
    "      self.tot_active += 1\n",
    "      self.tot_recruitable_active += 1\n",
    "      for l in range(self.num_layers):\n",
    "        for x in range(int(act_x-self.r),int(act_x+self.r+1)):\n",
    "          for y in range(int(act_y-self.r),int(act_y+self.r+1)):\n",
    "            if distance(act_x,act_y,x,y) <= self.r:\n",
    "              xi = x % self.width\n",
    "              yi = y % self.width\n",
    "              if l != act_l: # spread the activity across layers\n",
    "                if np.random.rand() < self.trans: # transfer the activity\n",
    "                  self.active_neighbors[l, xi,yi] += 1\n",
    "              else: # if it is the same layer\n",
    "                self.active_neighbors[l, xi,yi] += 1\n",
    "              if self.active_neighbors[l, xi,yi] == self.t and \\\n",
    "                not self.active[l, xi,yi]:\n",
    "                if self.recruitable[l, xi,yi]:\n",
    "                  self.activated.append([l, xi,yi])\n",
    "                else: # activate the node but don't propagate the activity\n",
    "                  self.active[l,xi,yi] = True\n",
    "                  self.tot_active += 1\n",
    "\n",
    "  def activate(self):\n",
    "    \"\"\" activate a random potentially active node \"\"\"\n",
    "    if self.fraction_active() > 0.95:\n",
    "      return\n",
    "      \n",
    "    # pick a random point\n",
    "    while True:\n",
    "      l = np.random.randint(0,self.num_layers)\n",
    "      x = np.random.randint(0,self.width)\n",
    "      y = np. random.randint(0,self.width)\n",
    "      if (self.recruitable[l,x,y] and not self.active[l,x,y]):\n",
    "        break\n",
    "    self.activated.append([l,x,y])\n",
    "    self.propagate()\n",
    "\n",
    "  def correlation(self):\n",
    "    \"\"\" returns the correlation between the left and right images \"\"\"\n",
    "    # the total number of activations in common\n",
    "    # same_count = len(where(self.active[0,:,:] == self.active[1,:,:])[0])\n",
    "    # return float(same_count) / (self.width * self.width)\n",
    "    \n",
    "    # create an activity matrix of 0's and 1's (instead of True and False)\n",
    "    if self.num_layers < 2:\n",
    "      print(\"monocular models cannot have correlations between eye layers\")\n",
    "      return 0\n",
    "    w = self.width\n",
    "    active01 = np.zeros([2,w,w],int)\n",
    "    active01[where(self.active)] = 1\n",
    "    \n",
    "    mean0 = active01[0,:,:].mean()\n",
    "    mean1 = active01[1,:,:].mean()\n",
    "    std0 = active01[0,:,:].std()\n",
    "    std1 = active01[1,:,:].std()\n",
    "    cov = ((active01[0,:,:] - mean0) * (active01[1,:,:] - mean1)).mean()\n",
    "    return cov / (std0 * std1)\n",
    "    \n",
    "  def make_img_mat(self, show_img=True):\n",
    "    \"\"\" return a matrix of 1's and 0's showing the activity in both layers \"\"\"\n",
    "    img_array = np.zeros([self.num_layers,self.width,self.width])\n",
    "    border_width = 10 if self.num_layers > 1 else 0\n",
    "    w = self.width\n",
    "    for l in range(self.num_layers):\n",
    "        img = np.zeros([w, w], float)\n",
    "        for x in range(0,w-1):\n",
    "            for y in range(0,w-1):\n",
    "                if self.active[l,x,y]:\n",
    "                    img[x,y] = 1           \n",
    "    \n",
    "        img_array[l] = img         \n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbsends/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:118: UserWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    }
   ],
   "source": [
    "feg = []\n",
    "seg = []\n",
    "\n",
    "for gg in range(10):\n",
    "    patches_1 = []\n",
    "    patches_2 = []\n",
    "    for n in range(10):\n",
    "        seed = randint(1,100)\n",
    "        # Generate the spontaneous activity patterns\n",
    "        L = LGN(width = 128, p = 0.7, r = 3, t = 4, trans = 0.05, make_wave = True, num_layers=2, random_seed=seed)\n",
    "        # Save patterns as images\n",
    "        images = L.make_img_mat()\n",
    "\n",
    "        # Generate 16x16 image patches for both left and right eye using a sliding window\n",
    "        patches_1.append(image.extract_patches_2d(images[0], (16, 16)))\n",
    "        patches_2.append(image.extract_patches_2d(images[1], (16, 16)))\n",
    "\n",
    "    patches_1 = np.array(patches_1)\n",
    "    patches_2 = np.array(patches_2)\n",
    "\n",
    "    blacklist = []\n",
    "\n",
    "    for x in range(0,patches_1.shape[0]):\n",
    "        if patches_1[x].std() == 0.0:\n",
    "            blacklist.append(x)\n",
    "            continue\n",
    "                #add to black list\n",
    "\n",
    "        if patches_2[x].std() == 0.0:\n",
    "            blacklist.append(x)\n",
    "            #add to black list\n",
    "\n",
    "    blacklist = np.array(blacklist)\n",
    "    if (blacklist.shape[0] != 0):\n",
    "        patches_1 = np.delete(patches_1, blacklist, axis=0)\n",
    "        patches_2 = np.delete(patches_2, blacklist, axis=0)\n",
    "            #removes boring patches (the patches with no activity!)\n",
    "\n",
    "    patches_1 = patches_1.reshape((patches_1.shape[0]*patches_1.shape[1]),16,16)\n",
    "    patches_2 = patches_2.reshape((patches_2.shape[0]*patches_2.shape[1]),16,16)\n",
    "\n",
    "    # Reshape the array to the shape (patches, the size of the patches)\n",
    "    reshaped_patches_1 = patches_1.reshape(-1, patches_1.shape[1]*patches_1.shape[1])\n",
    "    reshaped_patches_2 = patches_2.reshape(-1, patches_2.shape[1]*patches_2.shape[1])\n",
    "    composite_patches = np.concatenate((reshaped_patches_1,reshaped_patches_2),axis=1)\n",
    "\n",
    "    # Number of components to create/use\n",
    "    n_ica_components = 50\n",
    "\n",
    "    # Run ICA on all the patches and return generated components\n",
    "    icatemp = FastICA(n_components=n_ica_components, random_state=1) # note, sensitive to n_components\n",
    "    icafit_1 = icatemp.fit(composite_patches)\n",
    "    ica_comp_1 = icafit_1.components_\n",
    "\n",
    "    # Get the components from both eye layers\n",
    "    first_eye = ica_comp_1[:, 0:patches_1.shape[1]**2]\n",
    "    second_eye = ica_comp_1[:, patches_1.shape[1]**2:]\n",
    "\n",
    "    # Reshape components (for easier plotting)\n",
    "    results_1 = first_eye.reshape(-1,patches_1.shape[1],patches_1.shape[1])\n",
    "    results_2 = second_eye.reshape(-1,patches_1.shape[1],patches_1.shape[1])\n",
    "    feg.append(results_1)\n",
    "    seg.append(results_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feg = np.array(feg)\n",
    "seg = np.array(seg)\n",
    "first_eye_gabors = np.array(feg).reshape((feg.shape[0] * feg.shape[1]),16,16)\n",
    "second_eye_gabors = np.array(seg).reshape((seg.shape[0] * seg.shape[1]),16,16)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(first_eye_gabors[499])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_eye_gabors[0])\n",
    "plt.show()\n",
    "\n",
    "print(first_eye_gabors[0].shape)\n",
    "\n",
    "auto = open_norm(\"shift5_70patch.png\",verbose=False)\n",
    "\n",
    "initi = True\n",
    "\n",
    "for x in range(0,first_eye_gabors.shape[0]):\n",
    "    am1 = double_convolve(first_eye_gabors[x], second_eye_gabors[x], auto,70)\n",
    "    dm1 = linear_convolution(first_eye_gabors[x], second_eye_gabors[x])\n",
    "    sd1 = scale_disparity(am1,dm1)\n",
    "    if initi == True:\n",
    "        ca = sd1\n",
    "        initi = False\n",
    "    else:\n",
    "        ca = ca + sd1\n",
    "\n",
    "depth_estimate = np.zeros([ca.shape[0],ca.shape[1]])\n",
    "\n",
    "for x in range(ca.shape[0]):\n",
    "    for y in range(ca.shape[1]):\n",
    "        peak = np.abs(np.argmax(np.abs(ca[x,y]))-16)\n",
    "        depth_estimate[x,y] = peak\n",
    "        \n",
    "        \n",
    "plt.imshow(depth_estimate[0:,70:], cmap=\"binary\")\n",
    "plt.show()\n",
    "dm = np.array(PIL.Image.open(\"dm.png\").convert(\"L\"))\n",
    "corr = np.corrcoef(depth_estimate[0:,70:].flatten(),dm[0:,70:].flatten())[0,1]\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = double_convolve(first_eye_gabors[200], second_eye_gabors[200], auto,70)\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "\n",
    "dm1 = linear_convolution(first_eye_gabors[200], second_eye_gabors[200])\n",
    "plt.plot(dm1)\n",
    "plt.show()\n",
    "\n",
    "ca = scale_disparity(x,dm1)\n",
    "\n",
    "depth_estimate = np.zeros([ca.shape[0],ca.shape[1]])\n",
    "\n",
    "for x in range(ca.shape[0]):\n",
    "    for y in range(ca.shape[1]):\n",
    "        peak = np.abs(np.argmax(np.abs(ca[x,y]))-16)\n",
    "        depth_estimate[x,y] = peak\n",
    "        \n",
    "        \n",
    "plt.imshow(depth_estimate[0:,70:], cmap=\"binary\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
