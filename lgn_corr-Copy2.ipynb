{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import pylab\n",
    "import hashlib\n",
    "import progressbar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.feature_extraction import image as skimage\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_gabor(size, shift, sigma, rotation, phase_shift, frequency):\n",
    "    radius = (int((size[0]/2.0)), int((size[1]/2.0)))\n",
    "    [x, y] = np.meshgrid(range(-radius[0], radius[0]), range(-radius[1], radius[1])) # a BUG is fixed in this line\n",
    "    x = x - int(shift[0])\n",
    "    y = y - int(shift[1])\n",
    "    x = x * frequency\n",
    "    y = y * frequency\n",
    "    tmp = x * np.cos(rotation) + y * np.sin(rotation) + phase_shift\n",
    "    radius = (int(size[0]/2.0), int(size[1]/2.0))\n",
    "    [x, y] = np.meshgrid(range(-radius[0], radius[0]), range(-radius[1], radius[1])) # a BUG is fixed in this line\n",
    "    \n",
    "    x = x - int(shift[0])\n",
    "    y = y - int(shift[1])\n",
    "    x1 = x * np.cos(rotation) + y * np.sin(rotation)\n",
    "    y1 = -x * np.sin(rotation) + y * np.cos(rotation)\n",
    "    \n",
    "    sinusoid = np.cos(tmp)\n",
    "    \n",
    "    gauss = np.e * np.exp(np.negative(0.5 * ((x1**2 / sigma[0]**2) + (y1**2 / sigma[1]**2)))) \n",
    "    gauss = gauss / 2*np.pi * sigma[0] * sigma[1]\n",
    "    \n",
    "    gabor = gauss * sinusoid\n",
    "    return gabor\n",
    "\n",
    "def open_norm(path,verbose=False):\n",
    "    raw = np.array(Image.open(path).convert(\"L\"))\n",
    "    norm = (raw - np.mean(raw)) / np.std(raw)\n",
    "    \n",
    "    if verbose:\n",
    "        return raw, norm\n",
    "    else:\n",
    "        return norm\n",
    "    \n",
    "def linear_convolution(center, slide): \n",
    "    if (center.shape != slide.shape):\n",
    "        return\n",
    "    padded_slide = np.zeros((center.shape[0],center.shape[1]*3))\n",
    "    padded_slide[0:,center.shape[1]:center.shape[1]*2] = center\n",
    "    #plt.imshow(padded_slide,origin=\"lower\")\n",
    "    #plt.show()\n",
    "    estimate = np.zeros([center.shape[1]*2])\n",
    "    for x in range(center.shape[1]*2):\n",
    "        dot = np.sum(padded_slide[0:,0+x:center.shape[1]+x] * slide)\n",
    "        estimate[x] = dot\n",
    "    #plt.plot(estimate)\n",
    "    #plt.show()\n",
    "    return np.abs(estimate)\n",
    "    \n",
    "def double_convolve(normal, shifted, image, pupillary_distance):\n",
    "    \n",
    "    #CHECKOUT https://github.com/maweigert/gputools\n",
    "    #probably VERY advantageous to switch over to GPU for convolutions!\n",
    "    \n",
    "    normal_convolved = signal.convolve2d(image, normal, boundary='symm', mode='same')\n",
    "    shifted_convolved = signal.convolve2d(image, shifted, boundary='symm', mode='same')\n",
    "    \n",
    "    return_shape = image.shape\n",
    "    \n",
    "    realigned = np.zeros(return_shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    normal_convolved = normal_convolved[0:,0:-pupillary_distance]\n",
    "    shifted_convolved = shifted_convolved[0:,pupillary_distance:]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    diff = np.subtract(normal_convolved, shifted_convolved)\n",
    "    mul = normal_convolved * shifted_convolved\n",
    "    #plt.imshow(mul,cmap=\"nipy_spectral\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #REMOVE BELOW COMMENTS TO THRESH SUBHALF VALUES\n",
    "    #low_values_flags = mul <= 0 #mul.max()*0.5  # Where values are low\n",
    "    #mul[low_values_flags] = 0  # All low values set to 0\n",
    "    realigned[0:,pupillary_distance:] = mul\n",
    "    return np.abs(mul)\n",
    "\n",
    "def scale_disparity(activity_map, disparity_map):\n",
    "    scaled_disparity = np.zeros([activity_map.shape[0],activity_map.shape[1],disparity_map.shape[0]])\n",
    "    scaled_disparity[:,:] = disparity_map\n",
    "    for x in range(activity_map.shape[0]):\n",
    "        for y in range(activity_map.shape[1]):\n",
    "            scaled_disparity[x,y] = activity_map[x,y] * scaled_disparity[x,y]\n",
    "            \n",
    "    return scaled_disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def distance(x0, y0, x1, y1):\n",
    "  return np.sqrt(pow(x0-x1,2) + pow(y0-y1,2))\n",
    "\n",
    "class LGN: \n",
    "  \"\"\"\n",
    "  this class defines a model which generates binocular spontaneous activity\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, width = 128, p = 0.5, r = 1.0, t = 1, trans = 0.0,\n",
    "    make_wave = True, num_layers=2, random_seed=0):\n",
    "    random.seed(random_seed)\n",
    "    self.width = width\n",
    "    self.p = p\n",
    "    self.r = r\n",
    "    self.t = t\n",
    "    self.trans = trans\n",
    "    self.num_layers = num_layers\n",
    "    if make_wave:\n",
    "      self.reset_wave()\n",
    "\n",
    "  def reset_wave(self):\n",
    "    \"\"\" create another random wave \"\"\"\n",
    "    # setting up the network\n",
    "    w = self.width\n",
    "    self.recruitable = np.random.rand(self.num_layers, w, w) < self.p\n",
    "    self.tot_recruitable = len(np.where(self.recruitable)[0])\n",
    "    self.tot_recruitable_active = 0\n",
    "    self.tot_active = 0\n",
    "    self.active = np.zeros([self.num_layers,w,w],bool)\n",
    "    self.active_neighbors = np.zeros([self.num_layers,w,w],int)\n",
    "    self.activated = []; # the recently active nodes\n",
    "    \n",
    "    if self.tot_recruitable > 0:\n",
    "      while self.fraction_active() < 0.2:\n",
    "        self.activate()  \n",
    "\n",
    "  def fraction_active(self):\n",
    "    \"\"\" returns the fraction of potentially recruitable cells which are active \"\"\"\n",
    "    if self.tot_recruitable > 0:\n",
    "      return float(self.tot_recruitable_active) / self.tot_recruitable\n",
    "    else:\n",
    "      return nan\n",
    "\n",
    "  def propagate(self):\n",
    "    \"\"\" propagate the activity if a valid node has been activated \"\"\"\n",
    "    # activated only has recruitable and currently inactive members\n",
    "    while len(self.activated) > 0:\n",
    "      act_l, act_x, act_y = self.activated.pop()\n",
    "      self.active[act_l,act_x,act_y] = True\n",
    "      self.tot_active += 1\n",
    "      self.tot_recruitable_active += 1\n",
    "      for l in range(self.num_layers):\n",
    "        for x in range(int(act_x-self.r),int(act_x+self.r+1)):\n",
    "          for y in range(int(act_y-self.r),int(act_y+self.r+1)):\n",
    "            if distance(act_x,act_y,x,y) <= self.r:\n",
    "              xi = x % self.width\n",
    "              yi = y % self.width\n",
    "              if l != act_l: # spread the activity across layers\n",
    "                if np.random.rand() < self.trans: # transfer the activity\n",
    "                  self.active_neighbors[l, xi,yi] += 1\n",
    "              else: # if it is the same layer\n",
    "                self.active_neighbors[l, xi,yi] += 1\n",
    "              if self.active_neighbors[l, xi,yi] == self.t and \\\n",
    "                not self.active[l, xi,yi]:\n",
    "                if self.recruitable[l, xi,yi]:\n",
    "                  self.activated.append([l, xi,yi])\n",
    "                else: # activate the node but don't propagate the activity\n",
    "                  self.active[l,xi,yi] = True\n",
    "                  self.tot_active += 1\n",
    "\n",
    "  def activate(self):\n",
    "    \"\"\" activate a random potentially active node \"\"\"\n",
    "    if self.fraction_active() > 0.95:\n",
    "      return\n",
    "      \n",
    "    # pick a random point\n",
    "    while True:\n",
    "      l = np.random.randint(0,self.num_layers)\n",
    "      x = np.random.randint(0,self.width)\n",
    "      y = np. random.randint(0,self.width)\n",
    "      if (self.recruitable[l,x,y] and not self.active[l,x,y]):\n",
    "        break\n",
    "    self.activated.append([l,x,y])\n",
    "    self.propagate()\n",
    "\n",
    "  def correlation(self):\n",
    "    \"\"\" returns the correlation between the left and right images \"\"\"\n",
    "    # the total number of activations in common\n",
    "    # same_count = len(where(self.active[0,:,:] == self.active[1,:,:])[0])\n",
    "    # return float(same_count) / (self.width * self.width)\n",
    "    \n",
    "    # create an activity matrix of 0's and 1's (instead of True and False)\n",
    "    if self.num_layers < 2:\n",
    "      print(\"monocular models cannot have correlations between eye layers\")\n",
    "      return 0\n",
    "    w = self.width\n",
    "    active01 = np.zeros([2,w,w],int)\n",
    "    active01[where(self.active)] = 1\n",
    "    \n",
    "    mean0 = active01[0,:,:].mean()\n",
    "    mean1 = active01[1,:,:].mean()\n",
    "    std0 = active01[0,:,:].std()\n",
    "    std1 = active01[1,:,:].std()\n",
    "    cov = ((active01[0,:,:] - mean0) * (active01[1,:,:] - mean1)).mean()\n",
    "    return cov / (std0 * std1)\n",
    "    \n",
    "  def make_img_mat(self, show_img=True):\n",
    "    \"\"\" return a matrix of 1's and 0's showing the activity in both layers \"\"\"\n",
    "    img_array = np.zeros([self.num_layers,self.width,self.width])\n",
    "    border_width = 10 if self.num_layers > 1 else 0\n",
    "    w = self.width\n",
    "    for l in range(self.num_layers):\n",
    "        img = np.zeros([w, w], float)\n",
    "        for x in range(0,w-1):\n",
    "            for y in range(0,w-1):\n",
    "                if self.active[l,x,y]:\n",
    "                    img[x,y] = 1           \n",
    "    \n",
    "        img_array[l] = img         \n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_patches(num_patches, patch_size, lgn_width, lgn_p, lgn_r, lgn_t, lgn_a):\n",
    "    half_comp = patch_size**2\n",
    "    patch_count = 0\n",
    "\n",
    "    while (patch_count < num_patches):\n",
    "        L = LGN(width = lgn_width, p = lgn_p, r = lgn_r, t = lgn_t, trans = lgn_a, make_wave = True, num_layers=2, random_seed=randint(1,100))\n",
    "        layer_activity = L.make_img_mat()\n",
    "        patches_1 = np.array(skimage.extract_patches_2d(layer_activity[0], (patch_size, patch_size)))\n",
    "        patches_2 = np.array(skimage.extract_patches_2d(layer_activity[1], (patch_size, patch_size)))\n",
    "        reshaped_patches_1 = patches_1.reshape(-1, patches_1.shape[1]*patches_1.shape[1])\n",
    "        reshaped_patches_2 = patches_2.reshape(-1, patches_2.shape[1]*patches_2.shape[1])\n",
    "        composite_patches = np.concatenate((reshaped_patches_1,reshaped_patches_2),axis=1)\n",
    "        blacklist = []        \n",
    "        for x in range(composite_patches.shape[0]):\n",
    "            if composite_patches[x][:half_comp].std() == 0.0 or composite_patches[x][half_comp:].std() == 0.0:\n",
    "                blacklist.append(x)\n",
    "        composite_patches = np.delete(composite_patches, np.array(blacklist), axis=0)\n",
    "        if (patch_count == 0):\n",
    "            patch_base = composite_patches\n",
    "        else:\n",
    "            patch_base = np.append(patch_base, composite_patches, axis=0)\n",
    "        patch_count = patch_base.shape[0]\n",
    "\n",
    "    return patch_base[:num_patches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_ica(num_components, patches):\n",
    "    # Run ICA on all the patches and return generated components\n",
    "    ica_instance = FastICA(n_components=num_components, random_state=1,max_iter=1000) # note, sensitive to n_components\n",
    "    icafit = ica_instance.fit(patches)\n",
    "    ica_components = icafit.components_\n",
    "    return ica_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_filters(num_filters, num_components, num_patches, patch_size, lgn_width, lgn_p, lgn_r, lgn_t, lgn_a): \n",
    "    print(\"GENERATING FILTERS\")\n",
    "    bar = progressbar.ProgressBar(max_value=num_filters)\n",
    "    filter_count = 0\n",
    "    while (filter_count < num_filters):\n",
    "        patches = generate_patches(num_patches, patch_size, lgn_width, lgn_p, lgn_r, lgn_t, lgn_a)\n",
    "        filters = perform_ica(num_components, patches)\n",
    "        if (filter_count == 0):\n",
    "            filter_base = filters\n",
    "        else:\n",
    "            filter_base = np.append(filter_base, filters, axis=0)\n",
    "        filter_count = filter_base.shape[0]\n",
    "        if (filter_count < num_filters):\n",
    "            bar.update(filter_count)\n",
    "        else:\n",
    "            bar.update(num_filters)\n",
    "\n",
    "    return filter_base[:num_filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_filters(filters):\n",
    "    half_filter = int(filters.shape[1]/2)\n",
    "    filter_dim = int(np.sqrt(filters.shape[1]/2))\n",
    "    first_eye = filters[:, 0:half_filter].reshape(-1,filter_dim,filter_dim)\n",
    "    second_eye = filters[:, half_filter:].reshape(-1,filter_dim,filter_dim)\n",
    "    return (first_eye, second_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_disparity(first_eye, second_eye):\n",
    "    disparity_map = np.empty([first_eye.shape[0],first_eye.shape[1]*2])\n",
    "    for index in range(first_eye.shape[0]):\n",
    "        disparity = linear_convolution(first_eye[index], second_eye[index])\n",
    "        disparity_map[index] = disparity\n",
    "    return disparity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_disparity(disparity_map):\n",
    "    sum_disparity = np.sum(disparity_map, axis=0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        normalized_disparity = disparity_map / sum_disparity\n",
    "    return normalized_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_activity(autostereogram, asg_patch_size, first_eye, second_eye, disparity_map):\n",
    "    print(\"CALCULATING ACTIVITY\")\n",
    "    bar = progressbar.ProgressBar(max_value=first_eye.shape[0])\n",
    "    for index in range(first_eye.shape[0]):\n",
    "        #make this more elegant\n",
    "        convolution = double_convolve(first_eye[index], second_eye[index], autostereogram, asg_patch_size)\n",
    "        scaled_activity = scale_disparity(convolution,disparity_map[index])\n",
    "        if index == 0:\n",
    "            summed_activity = scaled_activity\n",
    "        else:\n",
    "            summed_activity = summed_activity + scaled_activity\n",
    "        bar.update(index)\n",
    "    bar.update(first_eye.shape[0])\n",
    "    return summed_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_depth(activity):\n",
    "    print(\"ESTIMATING DEPTH\")\n",
    "    depth_estimate = np.zeros([activity.shape[0],activity.shape[1]])\n",
    "    bar = progressbar.ProgressBar(max_value=activity.shape[0])\n",
    "    for x in range(activity.shape[0]):\n",
    "        for y in range(activity.shape[1]):\n",
    "            peak = np.abs(np.nanargmax(activity[x,y])-int(activity.shape[2]/2))\n",
    "            peak = np.nanargmax(activity[x,y])\n",
    "            depth_estimate[x,y] = peak\n",
    "        bar.update(x)\n",
    "    return depth_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING FILTERS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% (465 of 1000) |##########            | Elapsed Time: 0:02:59 ETA:  0:03:08"
     ]
    }
   ],
   "source": [
    "\n",
    "test = generate_filters(1000, 5, 5000, 16, 128, 0.14, 3, 2, 0.2)\n",
    "t = unpack_filters(test)\n",
    "dm = linear_disparity(t[0],t[1])\n",
    "nd = normalize_disparity(dm)\n",
    "\n",
    "\n",
    "auto = open_norm(\"shift5_70patch_small.png\",verbose=False)\n",
    "asg_patch_sz = 70\n",
    "act = generate_activity(auto, asg_patch_sz, t[0], t[1], nd)\n",
    "de = estimate_depth(act)\n",
    "plt.imshow(de)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runEx(pShift=0.0, R=3, Trans = 0.1):\n",
    "    \n",
    "    tarray = []\n",
    "    parray = []\n",
    "    carray = []\n",
    "    harray = []\n",
    "    \n",
    "    patch_size = 8\n",
    "    \n",
    "    for bigT in range(1,5):\n",
    "        bigP = bigT / (((np.pi * (3**2)/2))*1.1) + pShift\n",
    "        print(\"t: \", bigT)\n",
    "        print(\"p: \", bigP)\n",
    "\n",
    "        feg = []\n",
    "        seg = []\n",
    "\n",
    "        for gg in range(5):\n",
    "\n",
    "\n",
    "            patches_1 = []\n",
    "            patches_2 = []\n",
    "            for n in range(5):\n",
    "                seed = randint(1,100)\n",
    "                # Generate the spontaneous activity patterns\n",
    "                L = LGN(width = 64, p = bigP, r = R, t = bigT, trans = Trans, make_wave = True, num_layers=2, random_seed=seed)\n",
    "                # Save patterns as images\n",
    "                images = L.make_img_mat()\n",
    "\n",
    "                # Generate 16x16 image patches for both left and right eye using a sliding window\n",
    "                patches_1.append(image.extract_patches_2d(images[0], (patch_size, patch_size)))\n",
    "                patches_2.append(image.extract_patches_2d(images[1], (patch_size, patch_size)))\n",
    "\n",
    "            patches_1 = np.array(patches_1)\n",
    "            patches_2 = np.array(patches_2)\n",
    "\n",
    "            blacklist = []\n",
    "\n",
    "            for x in range(0,patches_1.shape[0]):\n",
    "                if patches_1[x].std() == 0.0:\n",
    "                    blacklist.append(x)\n",
    "                    continue\n",
    "                        #add to black list\n",
    "\n",
    "                if patches_2[x].std() == 0.0:\n",
    "                    blacklist.append(x)\n",
    "                    #add to black list\n",
    "\n",
    "            blacklist = np.array(blacklist)\n",
    "            if (blacklist.shape[0] != 0):\n",
    "                patches_1 = np.delete(patches_1, blacklist, axis=0)\n",
    "                patches_2 = np.delete(patches_2, blacklist, axis=0)\n",
    "                    #removes boring patches (the patches with no activity!)\n",
    "\n",
    "            patches_1 = patches_1.reshape((patches_1.shape[0]*patches_1.shape[1]),patch_size,patch_size)\n",
    "            patches_2 = patches_2.reshape((patches_2.shape[0]*patches_2.shape[1]),patch_size,patch_size)\n",
    "\n",
    "            # Reshape the array to the shape (patches, the size of the patches)\n",
    "            reshaped_patches_1 = patches_1.reshape(-1, patches_1.shape[1]*patches_1.shape[1])\n",
    "            reshaped_patches_2 = patches_2.reshape(-1, patches_2.shape[1]*patches_2.shape[1])\n",
    "            composite_patches = np.concatenate((reshaped_patches_1,reshaped_patches_2),axis=1)\n",
    "\n",
    "            # Number of components to create/use\n",
    "            n_ica_components = 20\n",
    "\n",
    "            # Run ICA on all the patches and return generated components\n",
    "            icatemp = FastICA(n_components=n_ica_components, random_state=1) # note, sensitive to n_components\n",
    "            icafit_1 = icatemp.fit(composite_patches)\n",
    "            ica_comp_1 = icafit_1.components_\n",
    "\n",
    "            # Get the components from both eye layers\n",
    "            first_eye = ica_comp_1[:, 0:patches_1.shape[1]**2]\n",
    "            second_eye = ica_comp_1[:, patches_1.shape[1]**2:]\n",
    "\n",
    "            # Reshape components (for easier plotting)\n",
    "            results_1 = first_eye.reshape(-1,patches_1.shape[1],patches_1.shape[1])\n",
    "            results_2 = second_eye.reshape(-1,patches_1.shape[1],patches_1.shape[1])\n",
    "            feg.append(results_1)\n",
    "            seg.append(results_2)\n",
    "\n",
    "\n",
    "\n",
    "        feg = np.array(feg)\n",
    "        seg = np.array(seg)\n",
    "        first_eye_gabors = np.array(feg).reshape((feg.shape[0] * feg.shape[1]),patch_size,patch_size)\n",
    "        second_eye_gabors = np.array(seg).reshape((seg.shape[0] * seg.shape[1]),patch_size,patch_size)\n",
    "        auto = open_norm(\"shift5_70patch.png\",verbose=False)\n",
    "\n",
    "        initi = True\n",
    "\n",
    "        for x in range(0,first_eye_gabors.shape[0]):\n",
    "            am1 = double_convolve(first_eye_gabors[x], second_eye_gabors[x], auto,70)\n",
    "            dm1 = linear_convolution(first_eye_gabors[x], second_eye_gabors[x])\n",
    "            if ((np.argmax(np.abs(dm1))-patch_size) != 0):\n",
    "                sd1 = scale_disparity(am1,dm1)\n",
    "                if initi == True:\n",
    "                    ca = sd1\n",
    "                    initi = False\n",
    "                else:\n",
    "                    ca = ca + sd1\n",
    "\n",
    "\n",
    "\n",
    "        depth_estimate = np.zeros([ca.shape[0],ca.shape[1]])\n",
    "\n",
    "        for x in range(ca.shape[0]):\n",
    "            for y in range(ca.shape[1]):\n",
    "                peak = np.abs(np.argmax(np.abs(ca[x,y]))-patch_size)\n",
    "                depth_estimate[x,y] = peak\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dm = np.array(Image.open(\"dm.png\").convert(\"L\"))\n",
    "        corr = np.corrcoef(depth_estimate[0:600,70:670].flatten(),dm[0:600,70:670].flatten())[0,1]\n",
    "        print(\"corr: \", corr)\n",
    "        \n",
    "\n",
    "\n",
    "        hasher = \"%f%f%f\" % (bigT, bigP, corr)\n",
    "        hasher = hashlib.sha256(hasher.encode('utf-8')).hexdigest()\n",
    "        hasher = hasher[:20]\n",
    "        print(\"hash: \", hasher)\n",
    "        namer = \"lgn_corr_data/%s.png\" % (hasher)\n",
    "\n",
    "        plt.imshow(depth_estimate[0:600,70:670], cmap=\"binary\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        saver = depth_estimate[0:600,70:670]\n",
    "        \n",
    "        act = (255.0 / saver.max() * (saver - saver.min())).astype(np.uint8)\n",
    "        sv = Image.fromarray(act)\n",
    "        sv = ImageOps.colorize(sv, (0,0,0), (0,255,0))\n",
    "        sv.save(namer)\n",
    "        \n",
    "        tarray.append(bigT)\n",
    "        parray.append(bigP)\n",
    "        carray.append(corr)\n",
    "        harray.append(hasher)\n",
    "\n",
    "        \n",
    "    return {\"t\": tarray, \"p\": parray, \"c\": carray, \"h\": harray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero = runEx(0.0)\n",
    "\n",
    "plusp1 = runEx(0.01)\n",
    "plusp2 = runEx(0.02)\n",
    "\n",
    "minusp1 = runEx(-0.01)\n",
    "minusp2 = runEx(-0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHANGE LINE 21\n",
    "\n",
    "print(zero)\n",
    "print()\n",
    "\n",
    "print(plusp1)\n",
    "print()\n",
    "\n",
    "print(plusp2)\n",
    "print()\n",
    "\n",
    "print(minusp1)\n",
    "print()\n",
    "\n",
    "print(minusp2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = []\n",
    "P = []\n",
    "C = []\n",
    "\n",
    "T.append(zero[\"t\"])\n",
    "T.append(plusp1[\"t\"])\n",
    "T.append(plusp2[\"t\"])\n",
    "T.append(minusp1[\"t\"])\n",
    "T.append(minusp2[\"t\"])\n",
    "T = np.array(T).flatten()\n",
    "\n",
    "P.append(zero[\"p\"])\n",
    "P.append(plusp1[\"p\"])\n",
    "P.append(plusp2[\"p\"])\n",
    "P.append(minusp1[\"p\"])\n",
    "P.append(minusp2[\"p\"])\n",
    "P = np.array(P).flatten()\n",
    "\n",
    "C.append(zero[\"c\"])\n",
    "C.append(plusp1[\"c\"])\n",
    "C.append(plusp2[\"c\"])\n",
    "C.append(minusp1[\"c\"])\n",
    "C.append(minusp2[\"c\"])\n",
    "C = np.array(C).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.column_stack((T,P))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xi = np.linspace(T.min(), T.max(), 100)\n",
    "yi = np.linspace(P.min(), P.max(), 100)\n",
    "xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "# interpolate\n",
    "zi = griddata(p, C, (xi, yi), method=\"cubic\")\n",
    "\n",
    "plt.contourf(xi, yi, zi)\n",
    "\n",
    "plt.title('FLAW: trans = 0.1, r = 3')\n",
    "\n",
    "\n",
    "h = plt.ylabel('P   ')\n",
    "h.set_rotation(0)\n",
    "plt.xlabel('T')\n",
    "\n",
    "\n",
    "plt.savefig(\"contour.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This cell intentionally left blank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{'t': [1, 2, 3, 4, 5, 6, 7, 8], 'p': [0.0643050275118769, 0.1286100550237538, 0.1929150825356307, 0.2572201100475076, 0.3215251375593845, 0.3858301650712614, 0.45013519258313833, 0.5144402200950152], 'c': [0.2271524872176735, 0.11748923387279109, 0.16814365075272392, 0.11891839158822315, 0.22924557006867541, 0.2021914390136689, 0.17564410008960482, 0.11591208048129203], 'h': ['2be4e854a3a8019f10ce', 'd7a4863ed4d821dd12da', '7574c16b165310f308f6', 'a29c1089edfd07b87cc4', 'd1cfe3053f6e64b2ae1f', 'c7cee8860f2a854d4979', '75012fbdb92846eac602', '054c4c7786a59a03ffc3']}\n",
    "\n",
    "{'t': [1, 2, 3, 4, 5, 6, 7, 8], 'p': [0.16430502751187692, 0.2286100550237538, 0.2929150825356307, 0.35722011004750764, 0.4215251375593845, 0.4858301650712614, 0.5501351925831384, 0.6144402200950152], 'c': [0.17965148101740655, 0.18346965101910506, 0.19459529299072095, 0.076159217264992848, 0.15864535098727001, 0.13156357558363777, 0.14233424494430186, 0.22089215028050982], 'h': ['608afb5e7d3248462cbe', '9ccec377250821de4001', 'c7193270aa4c7ff3fe14', '237331c17e259f07b36d', '1d1fdd00cf923c6be634', '82ade1e5a50a29cb2e74', 'dff663d5d61841f782d4', '669ca9375b66d627319c']}\n",
    "\n",
    "{'t': [1, 2, 3, 4, 5, 6, 7, 8], 'p': [0.2643050275118769, 0.32861005502375384, 0.3929150825356307, 0.4572201100475076, 0.5215251375593846, 0.5858301650712614, 0.6501351925831383, 0.7144402200950153], 'c': [0.10099254151515953, 0.20184900352887408, 0.13151115566586377, 0.11472869083386326, 0.15515506356514958, 0.082535541773616827, 0.20066737038524315, 0.18114673542172366], 'h': ['922a020aa7cbd348cd7d', 'd7be78f247bcc037902f', 'ab69fc8b784e6c505b09', '70f34a8b12410be24ab5', '20c7bae346f1bb34373f', '350037822f2e8440525d', '8b2b88bae00683e7a873', '2b76bb991235ecacc4c5']}\n",
    "\n",
    "{'t': [1, 2, 3, 4, 5, 6, 7, 8], 'p': [-0.0356949724881231, 0.0286100550237538, 0.09291508253563069, 0.1572201100475076, 0.2215251375593845, 0.28583016507126136, 0.3501351925831383, 0.41444022009501524], 'c': [0.10247495422255036, 0.14378019690175797, 0.20006787356858022, 0.1611758406682812, 0.14768773606739419, 0.21104334560934948, 0.12958418492805665, 0.13361840455817844], 'h': ['a4a3af560d6846203328', 'a4cd5cacdbe45e034f43', 'bad2bdf032712b33681c', 'f52aee518e038af56d2a', '1d1392e1699c4c2c1fe3', '60568bc2f83ba088a340', 'ee2540a353631fdb3fac', '674586e1d14430f357e1']}\n",
    "\n",
    "{'t': [1, 2, 3, 4, 5, 6, 7, 8], 'p': [-0.13569497248812312, -0.0713899449762462, -0.007084917464369317, 0.0572201100475076, 0.12152513755938449, 0.18583016507126138, 0.2501351925831383, 0.3144402200950152], 'c': [0.20084754601983387, 0.19575105078370753, 0.15312192862797003, 0.12826216298868348, 0.19207832092450744, 0.19047879777972482, 0.21390114541489133, 0.22404160860323402], 'h': ['a1b6cc26fb7a61d4e4c8', '7217e4ac82668cb964c3', 'e02d0dfcd0219c93d7e9', '990a591cfe25e5dafa12', '5f187492118f439c15cc', 'bf9fc67a782462dfe82c', '3dfb8bd11d355b51dd0e', 'b5ff87bce29f3fe272b0']}\n",
    "\n",
    "\n",
    "\n",
    "t = [1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8]\n",
    " \n",
    " p = [ 0.06430503  0.12861006  0.19291508  0.25722011  0.32152514  0.38583017\n",
    "  0.45013519  0.51444022  0.16430503  0.22861006  0.29291508  0.35722011\n",
    "  0.42152514  0.48583017  0.55013519  0.61444022  0.26430503  0.32861006\n",
    "  0.39291508  0.45722011  0.52152514  0.58583017  0.65013519  0.71444022\n",
    " -0.03569497  0.02861006  0.09291508  0.15722011  0.22152514  0.28583017\n",
    "  0.35013519  0.41444022 -0.13569497 -0.07138994 -0.00708492  0.05722011\n",
    "  0.12152514  0.18583017  0.25013519  0.31444022]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c = [ 0.22715249  0.11748923  0.16814365  0.11891839  0.22924557  0.20219144\n",
    "  0.1756441   0.11591208  0.17965148  0.18346965  0.19459529  0.07615922\n",
    "  0.15864535  0.13156358  0.14233424  0.22089215  0.10099254  0.201849\n",
    "  0.13151116  0.11472869  0.15515506  0.08253554  0.20066737  0.18114674\n",
    "  0.10247495  0.1437802   0.20006787  0.16117584  0.14768774  0.21104335\n",
    "  0.12958418  0.1336184   0.20084755  0.19575105  0.15312193  0.12826216\n",
    "  0.19207832  0.1904788   0.21390115  0.22404161]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//////////////////////////////////// r2 //////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{'t': [1, 2, 3], 'p': [0.0643050275118769, 0.1286100550237538, 0.1929150825356307], 'c': [0.1377634742857804, 0.14544935917455801, 0.15288387668259798], 'h': ['4bfaa1ecdc9434d1e6b1', '9169115640a7585626c5', '942e8421687c5501c75e']}\n",
    "\n",
    "{'t': [1, 2, 3], 'p': [0.0743050275118769, 0.13861005502375381, 0.2029150825356307], 'c': [0.13410292614588934, 0.17328774382671466, 0.21582283877716074], 'h': ['d8a03faf2694f876d523', 'd80062e7c68bbbe9f5df', '361a1fbce3edaf05892c']}\n",
    "\n",
    "{'t': [1, 2, 3], 'p': [0.0843050275118769, 0.1486100550237538, 0.21291508253563068], 'c': [0.19929353870166028, 0.21228907033779296, 0.21630368862593366], 'h': ['49bcf7142cf4bf871cfb', 'f55f2f77af41b127be25', '44399eb5405b349e5268']}\n",
    "\n",
    "{'t': [1, 2, 3], 'p': [0.0543050275118769, 0.11861005502375381, 0.18291508253563069], 'c': [0.15707454586864894, 0.16889960493069478, 0.11172137044140341], 'h': ['6609816082c047a8e3de', 'f61c5d58deed5272fbc2', '9432d007955b2eff43d6']}\n",
    "\n",
    "{'t': [1, 2, 3], 'p': [0.0443050275118769, 0.1086100550237538, 0.1729150825356307], 'c': [0.14943104383301722, 0.20341405899828638, 0.20558845806693285], 'h': ['9667779334d0c940d3f5', '921ea736648dd558fe9d', '6dd15e388993d5f4a66f']}\n",
    "\n",
    "\n",
    "\n",
    "t = [1 2 3 1 2 3 1 2 3 1 2 3 1 2 3]\n",
    "\n",
    "p = [ 0.06430503  0.12861006  0.19291508  0.07430503  0.13861006  0.20291508\n",
    "  0.08430503  0.14861006  0.21291508  0.05430503  0.11861006  0.18291508\n",
    "  0.04430503  0.10861006  0.17291508]\n",
    "  \n",
    "c = [ 0.13776347  0.14544936  0.15288388  0.13410293  0.17328774  0.21582284\n",
    "  0.19929354  0.21228907  0.21630369  0.15707455  0.1688996   0.11172137\n",
    "  0.14943104  0.20341406  0.20558846]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feg = np.array(feg)\n",
    "seg = np.array(seg)\n",
    "first_eye_gabors = np.array(feg).reshape((feg.shape[0] * feg.shape[1]),16,16)\n",
    "second_eye_gabors = np.array(seg).reshape((seg.shape[0] * seg.shape[1]),16,16)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(first_eye_gabors[499])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv = PIL.ImageOps.colorize(sv, (0,0,0), (0,255,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(first_eye_gabors[0])\n",
    "plt.show()\n",
    "\n",
    "print(first_eye_gabors[0].shape)\n",
    "\n",
    "auto = open_norm(\"shift5_70patch.png\",verbose=False)\n",
    "\n",
    "initi = True\n",
    "\n",
    "for x in range(0,first_eye_gabors.shape[0]):\n",
    "    am1 = double_convolve(first_eye_gabors[x], second_eye_gabors[x], auto,70)\n",
    "    dm1 = linear_convolution(first_eye_gabors[x], second_eye_gabors[x])\n",
    "    if ((np.argmax(np.abs(dm1))-16) != 0):\n",
    "        sd1 = scale_disparity(am1,dm1)\n",
    "        if initi == True:\n",
    "            ca = sd1\n",
    "            initi = False\n",
    "        else:\n",
    "            ca = ca + sd1\n",
    "        \n",
    "\n",
    "\n",
    "depth_estimate = np.zeros([ca.shape[0],ca.shape[1]])\n",
    "\n",
    "for x in range(ca.shape[0]):\n",
    "    for y in range(ca.shape[1]):\n",
    "        peak = np.abs(np.argmax(np.abs(ca[x,y]))-16)\n",
    "        depth_estimate[x,y] = peak\n",
    "        \n",
    "        \n",
    "plt.imshow(depth_estimate[0:600,70:670], cmap=\"binary\")\n",
    "plt.show()\n",
    "dm = np.array(PIL.Image.open(\"dm.png\").convert(\"L\"))\n",
    "corr = np.corrcoef(depth_estimate[0:600,70:670].flatten(),dm[0:600,70:670].flatten())[0,1]\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "plt.imshow(depth_estimate[0:600,70:670])\n",
    "plt.savefig('foo.png', dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "am1 = double_convolve(first_eye_gabors[3], second_eye_gabors[3], auto,70)\n",
    "plt.imshow(am1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bigT in range(1,9):\n",
    "    bigP = bigT / (((np.pi * (3**2)/2))*1.1)\n",
    "    print(bigP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
